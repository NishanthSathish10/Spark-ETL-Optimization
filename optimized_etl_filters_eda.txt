--- Starting Optimized ETL Job (Final Clean Strategy) ---
Reading lookup table...
Reading Batch 1 (Legacy)...
Reading Batch 2 (Middle)...
Reading Batch 3 (Modern)...
Unioning datasets...

========================================
EDA SUMMARY: Raw Unioned Data (Pre-Clean)
========================================
--- First 5 Rows (Raw Unioned Data (Pre-Clean)) ---
+-------------------+-------------------+------------+------------+-------------+------------+---------------+-----------+
|pickup_datetime    |dropoff_datetime   |PULocationID|DOLocationID|trip_distance|total_amount|passenger_count|airport_fee|
+-------------------+-------------------+------------+------------+-------------+------------+---------------+-----------+
|2011-01-01 00:10:00|2011-01-01 00:12:00|145         |145         |0.0          |4.18        |4              |0.0        |
|2011-01-01 00:04:00|2011-01-01 00:13:00|264         |264         |0.0          |6.94        |4              |0.0        |
|2011-01-01 00:14:00|2011-01-01 00:16:00|264         |264         |0.0          |5.01        |4              |0.0        |
|2011-01-01 00:04:00|2011-01-01 00:06:00|146         |146         |0.0          |3.9         |5              |0.0        |
|2011-01-01 00:08:00|2011-01-01 00:08:00|146         |146         |0.0          |3.61        |5              |0.0        |
+-------------------+-------------------+------------+------------+-------------+------------+---------------+-----------+
only showing top 5 rows
--- Year Ranges (Raw Unioned Data (Pre-Clean)) ---
+---------------+---------------+----------------+----------------+
|min_pickup_year|max_pickup_year|min_dropoff_year|max_dropoff_year|
+---------------+---------------+----------------+----------------+
|           2001|           2098|            1900|            2253|
+---------------+---------------+----------------+----------------+

--- Numerical Statistics (Raw Unioned Data (Pre-Clean)) ---
+-------+-----------------+------------------+------------------+--------------------+
|summary|    trip_distance|      total_amount|   passenger_count|         airport_fee|
+-------+-----------------+------------------+------------------+--------------------+
|  count|       1438340823|        1438340823|        1428780443|          1267742078|
|   mean|6.087094372319375|16.213556089087263|1.6285380685323392|0.012760284785624982|
| stddev|6415.244038916491|319.31362151364823|1.2772464253420825|  0.1427573162341001|
|    min|    -4.08401244E7|           -2567.8|                 0|               -1.75|
|    25%|              1.0|               8.4|                 1|                 0.0|
|    50%|             1.72|              12.0|                 1|                 0.0|
|    75%|              3.2|              18.0|                 2|                 0.0|
|    max|    1.346190631E8|       1.0000015E7|               255|                1.75|
+-------+-----------------+------------------+------------------+--------------------+

========================================

Cleaning and calculating features...
Calculating trip duration...
Filtering invalid rows...
Performing BROADCAST Joins...

========================================
EDA SUMMARY: Final Cleaned Data
========================================
--- First 5 Rows (Final Cleaned Data) ---
+-------------------+-------------------+------------+------------+-------------+------------+---------------+-----------+------------------+--------------+---------------+
|pickup_datetime    |dropoff_datetime   |PULocationID|DOLocationID|trip_distance|total_amount|passenger_count|airport_fee|trip_duration_mins|pickup_borough|dropoff_borough|
+-------------------+-------------------+------------+------------+-------------+------------+---------------+-----------+------------------+--------------+---------------+
|2011-01-01 00:58:10|2011-01-01 01:15:35|138         |256         |8.0          |21.1        |1              |0.0        |17.42             |Queens        |Brooklyn       |
|2011-01-01 00:23:27|2011-01-01 00:39:39|170         |237         |1.6          |10.3        |1              |0.0        |16.2              |Manhattan     |Manhattan      |
|2011-01-01 00:42:08|2011-01-01 00:51:50|237         |170         |2.5          |9.1         |4              |0.0        |9.7               |Manhattan     |Manhattan      |
|2011-01-01 00:53:36|2011-01-01 01:17:43|170         |239         |3.9          |18.28       |2              |0.0        |24.12             |Manhattan     |Manhattan      |
|2011-01-01 00:37:47|2011-01-01 00:41:20|90          |90          |0.6          |5.1         |2              |0.0        |3.55              |Manhattan     |Manhattan      |
+-------------------+-------------------+------------+------------+-------------+------------+---------------+-----------+------------------+--------------+---------------+
only showing top 5 rows
--- Year Ranges (Final Cleaned Data) ---
+---------------+---------------+----------------+----------------+
|min_pickup_year|max_pickup_year|min_dropoff_year|max_dropoff_year|
+---------------+---------------+----------------+----------------+
|           2011|           2024|            2011|            2024|
+---------------+---------------+----------------+----------------+

--- Numerical Statistics (Final Cleaned Data) ---
+-------+-----------------+-----------------+------------------+-------------------+------------------+
|summary|    trip_distance|     total_amount|   passenger_count|        airport_fee|trip_duration_mins|
+-------+-----------------+-----------------+------------------+-------------------+------------------+
|  count|       1390203064|       1390203064|        1390203064|         1390203064|        1390203064|
|   mean|6.059788234807334|16.03519603879781| 1.627174711794478|0.01110099153831242|13.718528115465578|
| stddev|5137.530855513555|312.1473594859978|1.2734266815538005|0.13084419128305988|10.673000503751377|
|    min|             0.01|             0.01|                 0|                0.0|              1.02|
|    25%|             1.03|              8.5|                 1|                0.0|              6.68|
|    50%|             1.75|             12.0|                 1|                0.0|              11.0|
|    75%|              3.2|            17.94|                 2|                0.0|             17.42|
|    max|     5.90166093E7|      1.0000015E7|               254|               1.75|            239.98|
+-------+-----------------+-----------------+------------------+-------------------+------------------+

========================================

Writing final optimized dataset (coalesced)...
Traceback (most recent call last):
  File "/Users/nish/UMass/532 - Systems for Data Science/project/Spark-ETL-Optimization/optimized_etl.py", line 255, in <module>
  File "/Users/nish/UMass/532 - Systems for Data Science/project/Spark-ETL-Optimization/optimized_etl.py", line 249, in run_optimized_etl
  File "/Users/nish/UMass/532 - Systems for Data Science/project/Spark-ETL-Optimization/.venv/lib/python3.13/site-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/readwriter.py", line 2003, in parquet
    self._jwrite.parquet(path)
    ~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "/Users/nish/UMass/532 - Systems for Data Science/project/Spark-ETL-Optimization/.venv/lib/python3.13/site-packages/pyspark/python/lib/py4j-0.10.9.9-src.zip/py4j/java_gateway.py", line 1362, in __call__
    return_value = get_return_value(
        answer, self.gateway_client, self.target_id, self.name)
  File "/Users/nish/UMass/532 - Systems for Data Science/project/Spark-ETL-Optimization/.venv/lib/python3.13/site-packages/pyspark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 282, in deco
    return f(*a, **kw)
  File "/Users/nish/UMass/532 - Systems for Data Science/project/Spark-ETL-Optimization/.venv/lib/python3.13/site-packages/pyspark/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py", line 327, in get_return_value
    raise Py4JJavaError(
        "An error occurred while calling {0}{1}{2}.\n".
        format(target_id, ".", name), value)
py4j.protocol.Py4JJavaError: An error occurred while calling o449.parquet.
: org.apache.spark.SparkException: [SPARK_JOB_CANCELLED] Job 18 cancelled killed via Web UI SQLSTATE: XXKDA
	at org.apache.spark.errors.SparkCoreErrors$.sparkJobCancelled(SparkCoreErrors.scala:222)
	at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:2865)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3160)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$4(FileFormatWriter.scala:309)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:270)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:306)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:189)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:195)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:117)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:115)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:129)
	at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:402)
	at org.apache.spark.sql.execution.adaptive.ResultQueryStageExec.$anonfun$doMaterialize$1(QueryStageExec.scala:325)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$4(SQLExecution.scala:322)
	at org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$3(SQLExecution.scala:320)
	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$2(SQLExecution.scala:316)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1439)
	at org.apache.spark.util.LazyTry.get(LazyTry.scala:58)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:131)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:192)
	at org.apache.spark.sql.classic.DataFrameWriter.runCommand(DataFrameWriter.scala:622)
	at org.apache.spark.sql.classic.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:273)
	at org.apache.spark.sql.classic.DataFrameWriter.saveInternal(DataFrameWriter.scala:241)
	at org.apache.spark.sql.classic.DataFrameWriter.save(DataFrameWriter.scala:118)
	at org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:369)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:108)
	at java.base/java.lang.Thread.run(Thread.java:840)
	Suppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller
		at org.apache.spark.errors.SparkCoreErrors$.sparkJobCancelled(SparkCoreErrors.scala:222)
		at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:2865)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3160)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3141)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3130)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:50)
		at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)
		at org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)
		at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$4(FileFormatWriter.scala:309)
		at org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:270)
		at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:306)
		at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:189)
		at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:195)
		at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:117)
		at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:115)
		at org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:129)
		at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:402)
		at org.apache.spark.sql.execution.adaptive.ResultQueryStageExec.$anonfun$doMaterialize$1(QueryStageExec.scala:325)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$4(SQLExecution.scala:322)
		at org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$3(SQLExecution.scala:320)
		at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$2(SQLExecution.scala:316)
		at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
		at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
		at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
		... 1 more

